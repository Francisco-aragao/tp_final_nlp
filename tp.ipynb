{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/francisco/Documents/Francisco/Faculdade/7_Semestre/processamento_lingua_natural/tpFinal/tp_final_nlp/env_py/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-01-27 22:11:14.903217: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-01-27 22:11:14.958189: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1738026674.977279   21211 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1738026674.982446   21211 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-27 22:11:15.003426: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "data = pd.read_csv('./data/anime-dataset-2023.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see column names\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anime_id</th>\n",
       "      <th>Name</th>\n",
       "      <th>Genres</th>\n",
       "      <th>Synopsis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Cowboy Bebop</td>\n",
       "      <td>Action, Award Winning, Sci-Fi</td>\n",
       "      <td>Crime is timeless. By the year 2071, humanity ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Cowboy Bebop: Tengoku no Tobira</td>\n",
       "      <td>Action, Sci-Fi</td>\n",
       "      <td>Another day, another bounty—such is the life o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>Trigun</td>\n",
       "      <td>Action, Adventure, Sci-Fi</td>\n",
       "      <td>Vash the Stampede is the man with a $$60,000,0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>Witch Hunter Robin</td>\n",
       "      <td>Action, Drama, Mystery, Supernatural</td>\n",
       "      <td>Robin Sena is a powerful craft user drafted in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>Bouken Ou Beet</td>\n",
       "      <td>Adventure, Fantasy, Supernatural</td>\n",
       "      <td>It is the dark century and the people are suff...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   anime_id                             Name  \\\n",
       "0         1                     Cowboy Bebop   \n",
       "1         5  Cowboy Bebop: Tengoku no Tobira   \n",
       "2         6                           Trigun   \n",
       "3         7               Witch Hunter Robin   \n",
       "4         8                   Bouken Ou Beet   \n",
       "\n",
       "                                 Genres  \\\n",
       "0         Action, Award Winning, Sci-Fi   \n",
       "1                        Action, Sci-Fi   \n",
       "2             Action, Adventure, Sci-Fi   \n",
       "3  Action, Drama, Mystery, Supernatural   \n",
       "4      Adventure, Fantasy, Supernatural   \n",
       "\n",
       "                                            Synopsis  \n",
       "0  Crime is timeless. By the year 2071, humanity ...  \n",
       "1  Another day, another bounty—such is the life o...  \n",
       "2  Vash the Stampede is the man with a $$60,000,0...  \n",
       "3  Robin Sena is a powerful craft user drafted in...  \n",
       "4  It is the dark century and the people are suff...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get only the useful columns -> 'anime_id', 'Name', 'Genres', 'Synopsis'\n",
    "data = data[['anime_id', 'Name', 'Genres', 'Synopsis']]\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate over genres and preprocess them -> remove spaces, lowercase\n",
    "\n",
    "data['Genres'] = data['Genres'].apply(lambda x: x.replace(' ', '').lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anime_id</th>\n",
       "      <th>Name</th>\n",
       "      <th>Genres</th>\n",
       "      <th>Synopsis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Cowboy Bebop</td>\n",
       "      <td>action,awardwinning,sci-fi</td>\n",
       "      <td>Crime is timeless. By the year 2071, humanity ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Cowboy Bebop: Tengoku no Tobira</td>\n",
       "      <td>action,sci-fi</td>\n",
       "      <td>Another day, another bounty—such is the life o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>Trigun</td>\n",
       "      <td>action,adventure,sci-fi</td>\n",
       "      <td>Vash the Stampede is the man with a $$60,000,0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>Witch Hunter Robin</td>\n",
       "      <td>action,drama,mystery,supernatural</td>\n",
       "      <td>Robin Sena is a powerful craft user drafted in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>Bouken Ou Beet</td>\n",
       "      <td>adventure,fantasy,supernatural</td>\n",
       "      <td>It is the dark century and the people are suff...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>15</td>\n",
       "      <td>Eyeshield 21</td>\n",
       "      <td>sports</td>\n",
       "      <td>Shy, reserved, and small-statured, Deimon High...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>16</td>\n",
       "      <td>Hachimitsu to Clover</td>\n",
       "      <td>comedy,drama,romance</td>\n",
       "      <td>Yuuta Takemoto, a sophomore at an arts college...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>17</td>\n",
       "      <td>Hungry Heart: Wild Striker</td>\n",
       "      <td>comedy,sliceoflife,sports</td>\n",
       "      <td>As the younger brother of Japanese soccer star...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>18</td>\n",
       "      <td>Initial D Fourth Stage</td>\n",
       "      <td>action,drama</td>\n",
       "      <td>Takumi Fujiwara finally joins Ryousuke and Kei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>19</td>\n",
       "      <td>Monster</td>\n",
       "      <td>drama,mystery,suspense</td>\n",
       "      <td>Dr. Kenzou Tenma, an elite neurosurgeon recent...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   anime_id                             Name  \\\n",
       "0         1                     Cowboy Bebop   \n",
       "1         5  Cowboy Bebop: Tengoku no Tobira   \n",
       "2         6                           Trigun   \n",
       "3         7               Witch Hunter Robin   \n",
       "4         8                   Bouken Ou Beet   \n",
       "5        15                     Eyeshield 21   \n",
       "6        16             Hachimitsu to Clover   \n",
       "7        17       Hungry Heart: Wild Striker   \n",
       "8        18           Initial D Fourth Stage   \n",
       "9        19                          Monster   \n",
       "\n",
       "                              Genres  \\\n",
       "0         action,awardwinning,sci-fi   \n",
       "1                      action,sci-fi   \n",
       "2            action,adventure,sci-fi   \n",
       "3  action,drama,mystery,supernatural   \n",
       "4     adventure,fantasy,supernatural   \n",
       "5                             sports   \n",
       "6               comedy,drama,romance   \n",
       "7          comedy,sliceoflife,sports   \n",
       "8                       action,drama   \n",
       "9             drama,mystery,suspense   \n",
       "\n",
       "                                            Synopsis  \n",
       "0  Crime is timeless. By the year 2071, humanity ...  \n",
       "1  Another day, another bounty—such is the life o...  \n",
       "2  Vash the Stampede is the man with a $$60,000,0...  \n",
       "3  Robin Sena is a powerful craft user drafted in...  \n",
       "4  It is the dark century and the people are suff...  \n",
       "5  Shy, reserved, and small-statured, Deimon High...  \n",
       "6  Yuuta Takemoto, a sophomore at an arts college...  \n",
       "7  As the younger brother of Japanese soccer star...  \n",
       "8  Takumi Fujiwara finally joins Ryousuke and Kei...  \n",
       "9  Dr. Kenzou Tenma, an elite neurosurgeon recent...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into 2 parts -> train and test\n",
    "# train -> 80% of the data\n",
    "# test -> 20% of the data\n",
    "train = data.sample(frac=0.8, random_state=0)\n",
    "test = data.drop(train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((24905, 4), (19924, 4), (4981, 4))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape, train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['drama,fantasy,girlslove,romance', 'avantgarde,sports', 'comedy,sliceoflife', 'action,adventure,drama,sci-fi,supernatural', 'adventure,fantasy,romance,supernatural', 'avantgarde,drama,supernatural', 'boyslove,hentai', 'adventure,boyslove,comedy,fantasy', 'boyslove,erotica', 'action,adventure,sci-fi,supernatural', 'drama,sci-fi,suspense', 'drama,hentai', 'adventure,comedy,horror,romance,supernatural', 'adventure,comedy,gourmet', 'action,avantgarde,comedy,supernatural,ecchi', 'horror,supernatural,suspense', 'action,drama,mystery', 'adventure,drama,sliceoflife', 'action,comedy,fantasy,horror', 'horror,mystery,romance,supernatural', 'action,adventure,horror,mystery,sci-fi,suspense', 'fantasy,horror,supernatural,hentai', 'action,adventure,comedy,romance', 'action,adventure,suspense', 'boyslove,comedy,romance', 'fantasy,sci-fi,sliceoflife', 'action,comedy,romance,supernatural,hentai', 'adventure,drama,fantasy,romance,supernatural', 'action,comedy,fantasy,supernatural', 'action,comedy,girlslove,romance,ecchi', 'action,adventure,mystery', 'comedy,fantasy', 'fantasy', 'comedy,gourmet', 'hentai', 'comedy,mystery,sci-fi,supernatural', 'boyslove,drama,romance', 'adventure,sliceoflife', 'boyslove,comedy,drama,hentai', 'fantasy,horror', 'action,romance,supernatural', 'drama,sliceoflife,sports', 'action,fantasy,horror,romance', 'supernatural,suspense', 'action,adventure,comedy,sci-fi,ecchi', 'awardwinning,drama,fantasy,romance', 'action,adventure,fantasy,supernatural', 'action,adventure,comedy,ecchi', 'action,adventure,drama,fantasy,horror', 'awardwinning,drama,sliceoflife,supernatural', 'avantgarde', 'comedy,fantasy,supernatural,hentai', 'action,awardwinning,comedy', 'action,adventure,comedy,fantasy', 'action,drama,mystery,suspense', 'action,drama,fantasy,mystery', 'awardwinning,comedy', 'action,comedy,supernatural,hentai', 'girlslove,romance,sci-fi', 'action,comedy,fantasy,sci-fi,ecchi', 'comedy,fantasy,sci-fi,hentai', 'action,horror,suspense', 'boyslove,comedy,drama,fantasy', 'comedy,mystery,supernatural', 'comedy,fantasy,ecchi', 'action,adventure,comedy,drama,romance,sci-fi', 'adventure,avantgarde,awardwinning,comedy,romance', 'adventure,fantasy,romance,sci-fi', 'adventure,sci-fi,sports', 'action,romance,sci-fi,supernatural', 'boyslove,fantasy,erotica', 'adventure,fantasy,romance,hentai', 'horror,mystery,sci-fi', 'avantgarde,drama,horror,mystery,supernatural', 'action,drama,horror,romance,supernatural', 'horror,mystery,supernatural', 'action,comedy,drama,mystery,romance', 'action,comedy,drama,fantasy', 'comedy,drama,fantasy', 'action,adventure,awardwinning,drama,sci-fi', 'drama,fantasy,horror', 'comedy,fantasy,romance,supernatural,ecchi', 'adventure,comedy,drama,mystery,sci-fi', 'mystery,romance,sci-fi', 'action,drama,horror,romance,sci-fi,supernatural', 'adventure,comedy,drama,romance,sci-fi', 'comedy,drama,romance,sliceoflife', 'sports,hentai', 'action,supernatural,ecchi', 'awardwinning,mystery', 'avantgarde,comedy', 'adventure,comedy,mystery,romance', 'comedy,drama,mystery', 'awardwinning,fantasy', 'adventure,fantasy,romance,sci-fi,supernatural', 'comedy,sci-fi', 'horror,sci-fi,supernatural', 'suspense,hentai', 'comedy,drama,horror,romance', 'action,adventure,mystery,romance', 'action,adventure,comedy,supernatural', 'adventure,comedy,ecchi', 'action,comedy,fantasy,romance,sci-fi,ecchi', 'awardwinning,fantasy,horror,supernatural', 'adventure,comedy,mystery,supernatural', 'awardwinning,drama,sci-fi', 'action,avantgarde,drama,horror', 'action,adventure,supernatural,suspense', 'action,adventure,comedy,drama,romance,sci-fi,ecchi', 'comedy,horror,supernatural,suspense', 'drama,mystery,supernatural', 'action,adventure,comedy,romance,sci-fi', 'action,comedy,romance,sci-fi,ecchi', 'romance,supernatural', 'adventure,comedy,sports', 'adventure,romance', 'comedy,mystery,supernatural,ecchi', 'comedy,fantasy,romance,sci-fi,ecchi', 'mystery,suspense', 'action,adventure,fantasy,horror', 'adventure,comedy,fantasy,supernatural', 'action,comedy,fantasy,horror,romance,supernatural,hentai', 'drama,ecchi', 'action,adventure,drama,fantasy,sci-fi', 'action,drama,fantasy,mystery,romance', 'drama,fantasy,mystery', 'action,comedy,drama,fantasy,horror,romance,sci-fi', 'girlslove,sliceoflife', 'avantgarde,awardwinning,comedy', 'drama,fantasy,sliceoflife,supernatural', 'action,comedy,sports', 'comedy,gourmet,sliceoflife', 'boyslove,drama,fantasy,romance,sci-fi,supernatural', 'romance,ecchi', 'action,adventure,fantasy,ecchi', 'adventure,suspense', 'avantgarde,drama,fantasy,girlslove,romance', 'drama,suspense', 'adventure,drama,horror,mystery,sci-fi,supernatural,suspense', 'adventure', 'avantgarde,drama,sci-fi', 'action,drama,fantasy', 'action,drama,romance,sci-fi,ecchi', 'boyslove,comedy,drama', 'action,mystery,romance', 'comedy,drama,fantasy,mystery,romance', 'comedy,gourmet,supernatural', 'action,drama,sci-fi,supernatural', 'adventure,drama,horror,sci-fi,supernatural', 'horror,mystery,suspense', 'sliceoflife,hentai', 'fantasy,mystery,sci-fi', 'comedy,romance,sci-fi,sliceoflife,supernatural', 'action,adventure,fantasy,romance,sci-fi,supernatural', 'fantasy,romance,ecchi', 'awardwinning,comedy,drama,fantasy,mystery', 'action,adventure,comedy,romance,sci-fi,ecchi', 'awardwinning,comedy,sliceoflife,supernatural', 'mystery,romance,suspense', 'action,adventure,fantasy,mystery', 'action,avantgarde,fantasy,romance,sci-fi', 'sci-fi,supernatural,hentai', 'avantgarde,horror,mystery,supernatural,suspense', 'action,adventure,drama,sci-fi', 'sci-fi,hentai', 'adventure,drama,romance', 'fantasy,sports', 'action,adventure,comedy,fantasy,sports', 'adventure,fantasy,girlslove,mystery,ecchi', 'avantgarde,awardwinning,drama', 'boyslove,comedy,sliceoflife', 'comedy,fantasy,girlslove,ecchi', 'awardwinning,drama,mystery', 'comedy,sci-fi,hentai', 'action,adventure,sci-fi', 'awardwinning', 'adventure,comedy,drama,fantasy,romance,sci-fi', 'action,drama,romance,suspense', 'mystery,romance', 'action,romance,sci-fi', 'action,boyslove,horror,supernatural,suspense', 'action,adventure,horror,sci-fi,hentai', 'adventure,romance,sci-fi', 'boyslove,comedy,supernatural', 'action,romance,ecchi', 'action,comedy,sci-fi,supernatural', 'action,comedy,fantasy,sci-fi', 'drama,sports', 'romance,sci-fi', 'gourmet', 'boyslove,drama,romance,sci-fi', 'adventure,drama,sci-fi,supernatural', 'drama,romance,ecchi', 'comedy,romance,sliceoflife,sports', 'action,fantasy,sci-fi,supernatural', 'action,girlslove,sci-fi', 'action,mystery,supernatural', 'action,horror,mystery,supernatural,suspense', 'action,adventure,romance', 'adventure,comedy,fantasy,ecchi', 'horror,supernatural', 'awardwinning,drama,sports', 'action,adventure,fantasy,sci-fi', 'horror,sci-fi', 'comedy,drama,fantasy,sci-fi', 'action,horror,supernatural,ecchi', 'action,comedy,drama,fantasy,horror,ecchi', 'action,avantgarde,fantasy,sci-fi,supernatural,ecchi', 'action,drama,fantasy,romance,sci-fi', 'action', 'fantasy,supernatural', 'action,adventure,fantasy,sci-fi,supernatural', 'adventure,drama', 'action,adventure,comedy,mystery', 'comedy,drama,fantasy,romance', 'awardwinning,fantasy,sci-fi', 'comedy,sports', 'action,comedy,drama,sci-fi', 'action,adventure,avantgarde,mystery,supernatural', 'action,fantasy,girlslove,ecchi', 'avantgarde,horror,supernatural', 'action,comedy,drama,fantasy,sliceoflife,ecchi', 'drama,girlslove,horror', 'avantgarde,awardwinning,fantasy,horror,mystery,sci-fi,suspense', 'drama,fantasy,hentai', 'avantgarde,comedy,sliceoflife', 'action,comedy,drama,gourmet', 'avantgarde,drama,mystery,supernatural,suspense', 'boyslove,comedy,drama,romance,erotica', 'action,adventure,sci-fi,sports', 'action,awardwinning,drama,mystery', 'avantgarde,fantasy', 'adventure,fantasy,sliceoflife', 'comedy,romance,sliceoflife,supernatural,ecchi', 'gourmet,sliceoflife', 'action,awardwinning,drama,mystery,romance,sci-fi', 'action,comedy,mystery', 'action,adventure,awardwinning,supernatural', 'comedy,horror,supernatural', 'adventure,drama,fantasy,horror,sci-fi,supernatural', 'comedy,drama,fantasy,sliceoflife', 'drama,fantasy,suspense', 'action,drama,fantasy,horror,sci-fi,supernatural', 'comedy,mystery,sliceoflife', 'action,adventure,drama,horror,mystery,sci-fi', 'fantasy,sliceoflife,supernatural', 'action,adventure,comedy,drama,fantasy,romance,ecchi', 'avantgarde,sci-fi', 'avantgarde,comedy,horror', 'awardwinning,comedy,fantasy,ecchi', 'comedy,drama,fantasy,mystery', 'action,drama,horror,romance,sci-fi', 'boyslove,drama,sci-fi,erotica', 'action,adventure,fantasy,sci-fi,sliceoflife', 'action,fantasy,hentai', 'girlslove,ecchi', 'adventure,fantasy,mystery,suspense', 'avantgarde,drama,horror,romance,supernatural,suspense', 'action,adventure,fantasy,horror,sci-fi', 'comedy,horror,mystery,supernatural', 'action,avantgarde,horror,sci-fi', 'action,adventure,awardwinning,drama,fantasy', 'comedy,sci-fi,supernatural,ecchi', 'action,boyslove,drama,erotica', 'action,drama,fantasy,mystery,sci-fi', 'boyslove,sliceoflife,erotica', 'action,comedy,mystery,romance', 'action,comedy,sci-fi,sports', 'action,avantgarde,awardwinning,drama,sci-fi,suspense', 'adventure,comedy,sliceoflife,supernatural', 'awardwinning,comedy,girlslove', 'action,adventure,comedy,drama,supernatural', 'adventure,sci-fi,hentai', 'adventure,drama,mystery', 'comedy,mystery,romance,suspense', 'comedy,horror,sci-fi', 'drama,supernatural,hentai', 'fantasy,mystery', 'mystery,romance,sci-fi,suspense', 'action,boyslove,horror,sci-fi,supernatural', 'adventure,fantasy,horror,supernatural', 'adventure,comedy,drama,gourmet,romance', 'action,comedy,erotica', 'ecchi', 'comedy,sci-fi,sports', 'adventure,drama,horror,romance,sci-fi', 'comedy,romance,sliceoflife', 'action,fantasy,supernatural,hentai', 'comedy,mystery,supernatural,hentai', 'action,comedy,fantasy,supernatural,ecchi', 'action,sci-fi,ecchi', 'adventure,mystery,sliceoflife,supernatural', 'adventure,drama,horror,romance,supernatural,suspense', 'action,adventure,comedy,fantasy,sci-fi,supernatural', 'horror,mystery,supernatural,suspense', 'action,boyslove,drama,romance,supernatural', 'action,horror,supernatural,suspense', 'comedy,sci-fi,sports,ecchi', 'adventure,boyslove,drama,mystery', 'comedy,gourmet,sports', 'action,adventure,drama,fantasy,supernatural', 'comedy,fantasy,sci-fi,sports', 'comedy,girlslove', 'action,drama,mystery,supernatural', 'fantasy,romance,sliceoflife,supernatural', 'boyslove,comedy,drama,sci-fi,sliceoflife', 'comedy,mystery,sports', 'adventure,fantasy', 'action,fantasy', 'comedy,drama,romance,ecchi', 'boyslove,comedy,drama,fantasy,horror', 'comedy,drama,supernatural', 'avantgarde,horror', 'action,drama,horror,sci-fi,suspense', 'boyslove,comedy,drama,romance,sliceoflife', 'gourmet,suspense', 'comedy,fantasy,sports', 'action,adventure,comedy,drama,romance', 'action,drama,romance', 'action,comedy,mystery,sci-fi', 'boyslove,drama,fantasy,supernatural', 'action,comedy,romance,supernatural', 'action,comedy,girlslove', 'comedy,drama,ecchi', 'comedy,romance,supernatural,ecchi', 'action,adventure,comedy,fantasy,gourmet', 'action,comedy,fantasy,mystery', 'comedy,drama,sliceoflife,ecchi', 'action,adventure,awardwinning,drama,fantasy,romance', 'adventure,drama,sci-fi,suspense', 'action,adventure,comedy,romance,supernatural', 'action,supernatural,suspense', 'awardwinning,comedy,drama,fantasy,sliceoflife', 'action,comedy,drama,mystery,sci-fi,ecchi', 'comedy,drama,gourmet,romance', 'action,drama,mystery,romance,supernatural', 'boyslove,comedy', 'drama,fantasy,mystery,romance,supernatural', 'adventure,fantasy,horror,romance,supernatural', 'girlslove,sci-fi', 'boyslove,comedy,gourmet', 'girlslove,romance', 'action,drama,romance,supernatural', 'comedy,sports,ecchi', 'action,adventure,fantasy,horror,supernatural', 'romance', 'action,girlslove', 'drama,supernatural', 'action,adventure,fantasy,hentai', 'avantgarde,suspense', 'drama,romance', 'action,comedy,drama', 'adventure,sci-fi,sliceoflife', 'boyslove,romance', 'fantasy,romance', 'action,comedy,horror', 'adventure,drama,fantasy', 'action,boyslove,sci-fi,hentai', 'action,drama,sports', 'comedy,horror,romance,sci-fi', 'action,drama,mystery,romance,supernatural,suspense', 'comedy,fantasy,romance,ecchi', 'boyslove,romance,sliceoflife,sports', 'comedy,mystery,romance,supernatural', 'comedy,drama,fantasy,romance,sliceoflife,ecchi', 'adventure,mystery,sci-fi,supernatural', 'adventure,drama,fantasy,horror,mystery,supernatural', 'action,mystery', 'sports,supernatural', 'adventure,drama,fantasy,mystery,sci-fi,suspense', 'action,romance,hentai', 'action,adventure,fantasy', 'adventure,comedy,drama,fantasy,romance', 'drama,sci-fi,sliceoflife', 'action,adventure,horror,sci-fi,supernatural', 'drama,sliceoflife', 'boyslove,comedy,fantasy,romance,supernatural', 'action,suspense', 'action,comedy,drama,horror,mystery,sci-fi,supernatural,ecchi', 'awardwinning,romance', 'unknown', 'action,adventure,horror', 'adventure,awardwinning,sci-fi', 'fantasy,girlslove', 'adventure,horror,romance,supernatural', 'action,adventure,fantasy,romance,ecchi', 'comedy,drama,supernatural,ecchi', 'drama,mystery,sci-fi', 'action,fantasy,sliceoflife', 'action,drama,horror,sci-fi', 'adventure,comedy,sliceoflife', 'drama,horror', 'boyslove,comedy,drama,romance,sliceoflife,supernatural,erotica', 'mystery,supernatural,suspense', 'comedy,sci-fi,ecchi', 'adventure,comedy,fantasy,mystery,sci-fi', 'fantasy,mystery,supernatural', 'action,drama,fantasy,horror', 'action,avantgarde,drama,sci-fi', 'action,sliceoflife', 'fantasy,hentai', 'adventure,awardwinning,fantasy,suspense', 'drama,supernatural,ecchi', 'action,comedy,romance,sci-fi', 'comedy,horror', 'adventure,comedy,fantasy,sci-fi', 'comedy,romance,sci-fi,ecchi', 'boyslove,drama,hentai', 'comedy,horror,sports', 'action,fantasy,mystery,ecchi', 'action,adventure,drama,mystery', 'action,adventure,fantasy,romance,sci-fi', 'action,boyslove,drama,mystery,supernatural', 'drama,sci-fi', 'action,fantasy,sci-fi,sports', 'action,adventure,fantasy,horror,mystery,suspense', 'comedy,fantasy,sci-fi', 'awardwinning,supernatural', 'adventure,comedy,horror,supernatural', 'action,adventure,drama,fantasy', 'supernatural', 'comedy,erotica', 'action,sci-fi,supernatural', 'drama,fantasy,ecchi', 'fantasy,romance,supernatural', 'adventure,comedy,fantasy,hentai', 'action,adventure,mystery,sci-fi,supernatural', 'comedy,suspense', 'adventure,fantasy,mystery,sci-fi', 'adventure,horror', 'romance,suspense', 'awardwinning,fantasy,sliceoflife', 'action,comedy,sci-fi,ecchi', 'comedy,drama,mystery,sci-fi,ecchi', 'action,comedy,hentai', 'comedy,gourmet,mystery', 'adventure,sci-fi,suspense', 'action,adventure,awardwinning,drama,romance,sci-fi', 'adventure,fantasy,romance', 'comedy,fantasy,sliceoflife', 'drama,fantasy,mystery,romance', 'action,horror,sci-fi,suspense', 'action,comedy,fantasy,ecchi', 'boyslove,comedy,erotica', 'action,fantasy,mystery', 'adventure,awardwinning,mystery,sci-fi', 'adventure,horror,suspense', 'action,boyslove,sci-fi,suspense', 'action,comedy,fantasy', 'fantasy,gourmet,sliceoflife', 'action,adventure,comedy,fantasy,supernatural,hentai', 'adventure,boyslove,drama,fantasy', 'action,sci-fi,suspense', 'action,mystery,supernatural,ecchi', 'comedy,supernatural,suspense', 'action,comedy,romance', 'avantgarde,supernatural', 'boyslove,drama,supernatural', 'action,awardwinning,drama', 'action,comedy,drama,fantasy,romance,ecchi', 'adventure,comedy,drama,fantasy', 'adventure,sci-fi,ecchi', 'adventure,fantasy,horror,sci-fi,supernatural', 'action,mystery,sci-fi,suspense', 'adventure,boyslove,comedy,romance', 'action,avantgarde,horror,supernatural', 'fantasy,suspense,ecchi', 'comedy,fantasy,sci-fi,ecchi', 'comedy,sliceoflife,ecchi', 'action,sci-fi,hentai', 'action,drama,fantasy,sci-fi', 'avantgarde,mystery,supernatural', 'action,fantasy,girlslove', 'comedy,romance,supernatural', 'avantgarde,horror,suspense', 'comedy,ecchi', 'comedy,romance,sci-fi', 'action,comedy,drama,fantasy,romance', 'action,drama,romance,sci-fi', 'adventure,awardwinning,fantasy,romance,sci-fi', 'action,awardwinning,drama,sci-fi', 'adventure,comedy,romance,ecchi', 'action,boyslove,drama,supernatural', 'sliceoflife,supernatural', 'awardwinning,horror,supernatural', 'mystery,romance,ecchi', 'action,drama,hentai', 'romance,erotica', 'sports,suspense', 'avantgarde,fantasy,horror', 'avantgarde,drama,erotica', 'mystery', 'action,comedy,supernatural', 'action,adventure,fantasy,horror,romance', 'mystery,sci-fi', 'awardwinning,drama,fantasy,mystery', 'action,comedy,drama,fantasy,sliceoflife', 'drama,girlslove,romance,supernatural', 'awardwinning,comedy,supernatural', 'boyslove,comedy,romance,erotica', 'drama,girlslove,romance', 'comedy,drama,romance,hentai', 'action,fantasy,horror,supernatural', 'comedy,girlslove,ecchi', 'comedy,drama,romance', 'adventure,comedy,sci-fi,sports', 'adventure,awardwinning,comedy,fantasy', 'action,drama,fantasy,horror,supernatural', 'fantasy,romance,sliceoflife', 'mystery,sci-fi,supernatural', 'comedy,drama,mystery,supernatural', 'action,hentai', 'adventure,fantasy,gourmet', 'drama,fantasy,romance,sci-fi', 'comedy,supernatural', 'awardwinning,mystery,sci-fi', 'fantasy,sci-fi', 'comedy,drama,romance,sci-fi', 'action,awardwinning,sci-fi', 'drama,fantasy,romance,supernatural', 'avantgarde,awardwinning', 'fantasy,supernatural,hentai', 'drama,sci-fi,supernatural', 'comedy,fantasy,supernatural', 'avantgarde,erotica', 'action,comedy,fantasy,romance,sci-fi', 'action,adventure,drama,horror', 'drama,fantasy,horror,mystery,sci-fi,suspense', 'boyslove', 'action,awardwinning,romance,sci-fi', 'adventure,drama,supernatural', 'sports', 'action,adventure,drama,mystery,romance,sci-fi', 'adventure,fantasy,romance,ecchi', 'fantasy,sci-fi,supernatural', 'action,comedy,suspense', 'action,drama,horror,mystery,supernatural', 'action,comedy,horror,supernatural', 'action,horror,sci-fi', 'action,boyslove,comedy,supernatural', 'comedy,fantasy,sliceoflife,supernatural', 'action,adventure,comedy,fantasy,romance', 'comedy,fantasy,horror', 'action,comedy,girlslove,ecchi', 'comedy,romance,ecchi', 'horror', 'mystery,sci-fi,suspense', 'adventure,comedy,drama,romance,sci-fi,sports', 'action,adventure,comedy,drama,horror,mystery,romance,sci-fi,ecchi', 'comedy,fantasy,horror,supernatural', 'action,adventure,comedy,sci-fi,sports', 'action,supernatural,hentai', 'boyslove,sliceoflife', 'comedy,fantasy,hentai', 'action,adventure,drama,romance', 'action,comedy,drama,mystery', 'boyslove,comedy,sports', 'avantgarde,drama,suspense', 'drama,mystery,romance,hentai', 'avantgarde,awardwinning,drama,mystery,sci-fi,supernatural', 'action,mystery,sci-fi', 'action,adventure,supernatural', 'action,adventure,boyslove,fantasy,mystery,supernatural', 'action,horror', 'awardwinning,mystery,sci-fi,supernatural', 'adventure,awardwinning,drama,fantasy,romance', 'horror,suspense', 'comedy,romance,sliceoflife,ecchi', 'adventure,awardwinning,comedy', 'drama,horror,supernatural,ecchi', 'action,adventure,drama,mystery,sci-fi', 'action,sci-fi,sliceoflife', 'action,romance,sci-fi,ecchi', 'action,adventure,horror,sci-fi', 'adventure,drama,mystery,romance,sci-fi', 'adventure,ecchi', 'action,adventure,supernatural,ecchi', 'drama,fantasy,romance', 'adventure,awardwinning,mystery,romance,sci-fi', 'action,adventure,fantasy,romance,supernatural', 'adventure,awardwinning,comedy,fantasy,sci-fi', 'drama,fantasy,sci-fi', 'action,romance', 'awardwinning,drama,suspense', 'action,adventure,comedy,sci-fi', 'adventure,fantasy,mystery,romance,sci-fi,suspense', 'action,adventure,awardwinning,comedy,mystery', 'adventure,comedy,sci-fi,ecchi', 'action,avantgarde', 'drama,mystery,romance,supernatural', 'awardwinning,drama,mystery,supernatural', 'comedy,drama,romance,sliceoflife,supernatural', 'boyslove,drama,sci-fi', 'avantgarde,ecchi', 'action,horror,mystery,supernatural', 'comedy,fantasy,suspense', 'boyslove,drama,horror,mystery,supernatural', 'action,adventure,drama,sliceoflife', 'awardwinning,drama,romance,supernatural', 'adventure,drama,fantasy,romance', 'comedy,girlslove,romance', 'adventure,fantasy,supernatural', 'drama,horror,sci-fi', 'comedy,sliceoflife,supernatural', 'romance,sports,ecchi', 'comedy,hentai', 'adventure,drama,fantasy,erotica', 'comedy,drama,erotica', 'drama,horror,romance,supernatural', 'action,avantgarde,comedy,sci-fi', 'adventure,comedy,supernatural', 'adventure,comedy,fantasy,supernatural,ecchi', 'drama,fantasy,sliceoflife', 'action,adventure,awardwinning,sci-fi', 'boyslove,sci-fi,sliceoflife', 'avantgarde,drama,fantasy', 'comedy,romance', 'fantasy,sci-fi,suspense', 'comedy,fantasy,gourmet', 'sliceoflife,ecchi', 'action,awardwinning,fantasy', 'action,adventure,drama,fantasy,horror,supernatural', 'adventure,awardwinning,supernatural', 'action,adventure,awardwinning,comedy,ecchi', 'action,fantasy,sci-fi', 'comedy,drama,romance,sports', 'sci-fi,sliceoflife', 'adventure,comedy,romance,sports', 'action,adventure,comedy,drama,mystery', 'drama,horror,romance', 'action,awardwinning,comedy,drama,sci-fi', 'fantasy,mystery,romance', 'action,adventure,comedy,gourmet', 'drama,romance,erotica', 'action,adventure,ecchi', 'awardwinning,sci-fi', 'action,awardwinning,drama,suspense', 'comedy,drama,sliceoflife', 'avantgarde,sliceoflife,supernatural', 'action,sci-fi', 'action,awardwinning,drama,romance,sci-fi', 'awardwinning,drama,fantasy', 'comedy,girlslove,supernatural', 'comedy,girlslove,hentai', 'action,awardwinning', 'adventure,comedy,romance,sci-fi,ecchi', 'drama,romance,sci-fi,hentai', 'boyslove,drama,erotica', 'adventure,comedy,romance', 'avantgarde,comedy,sci-fi', 'awardwinning,drama,mystery,sci-fi', 'boyslove,comedy,mystery,romance', 'drama,romance,supernatural', 'action,adventure,drama,romance,sci-fi', 'action,adventure,comedy,drama,sci-fi', 'awardwinning,comedy,fantasy,sci-fi', 'adventure,drama,romance,sci-fi', 'comedy,fantasy,romance,sci-fi', 'adventure,comedy,fantasy,gourmet', 'adventure,drama,mystery,supernatural', 'boyslove,drama,romance,sliceoflife,erotica', 'action,horror,mystery,romance,supernatural', 'comedy,mystery,romance', 'action,fantasy,romance,supernatural', 'action,sci-fi,sports', 'boyslove,drama,romance,sports,erotica', 'adventure,drama,sci-fi', 'girlslove,hentai', 'action,drama,suspense', 'action,drama,horror,sci-fi,supernatural', 'comedy,drama,romance,sci-fi,ecchi', 'comedy,drama,fantasy,romance,ecchi', 'awardwinning,mystery,romance,sci-fi,suspense', 'sliceoflife,sports', 'adventure,fantasy,ecchi', 'action,boyslove,fantasy,supernatural', 'drama,fantasy,supernatural', 'action,horror,supernatural', 'action,adventure,awardwinning,comedy,drama,fantasy', 'action,adventure,awardwinning,comedy,drama,romance', 'action,adventure,comedy,fantasy,romance,ecchi', 'awardwinning,sports', 'action,comedy,gourmet', 'action,drama,mystery,supernatural,suspense', 'awardwinning,drama,mystery,suspense', 'avantgarde,comedy,drama,sci-fi', 'comedy,fantasy,mystery', 'comedy,girlslove,sci-fi', 'action,horror,sci-fi,supernatural', 'action,awardwinning,mystery,sci-fi', 'comedy,fantasy,romance', 'comedy,mystery', 'fantasy,ecchi', 'adventure,comedy,drama,fantasy,sci-fi,sliceoflife,supernatural', 'awardwinning,drama,sci-fi,supernatural', 'action,adventure,drama,fantasy,mystery', 'horror,romance', 'adventure,drama,fantasy,horror,supernatural', 'action,comedy,supernatural,ecchi', 'sci-fi,suspense', 'awardwinning,romance,sliceoflife', 'drama,fantasy,romance,sci-fi,supernatural,suspense', 'awardwinning,drama', 'action,fantasy,horror,sci-fi', 'awardwinning,comedy,drama,sci-fi', 'comedy,mystery,romance,ecchi', 'action,comedy,mystery,supernatural', 'action,fantasy,ecchi', 'drama,gourmet,romance', 'action,comedy,fantasy,romance,ecchi', 'adventure,fantasy,horror,hentai', 'avantgarde,comedy,drama,mystery', 'gourmet,ecchi', 'adventure,fantasy,sports', 'action,fantasy,gourmet,ecchi', 'action,comedy,romance,ecchi', 'erotica', 'action,fantasy,romance', 'drama,mystery,romance', 'avantgarde,fantasy,horror,hentai', 'drama,girlslove,sci-fi', 'adventure,comedy', 'action,supernatural', 'action,sci-fi,supernatural,suspense', 'action,drama,mystery,romance', 'action,mystery,sci-fi,supernatural', 'adventure,drama,romance,supernatural', 'action,comedy,horror,supernatural,suspense', 'drama,romance,sports', 'action,ecchi', 'action,comedy,drama,sports', 'comedy,drama', 'awardwinning,comedy,drama,fantasy,romance', 'drama,fantasy,girlslove', 'action,adventure,comedy,fantasy,sliceoflife', 'girlslove,supernatural,hentai', 'drama,fantasy,sports', 'awardwinning,drama,romance,sci-fi', 'action,adventure,romance,sci-fi', 'adventure,comedy,sci-fi,sliceoflife', 'drama,horror,supernatural', 'sci-fi,ecchi', 'adventure,drama,fantasy,sci-fi', 'action,adventure,drama,supernatural', 'avantgarde,drama,romance', 'awardwinning,drama,fantasy,sliceoflife', 'action,adventure,comedy,mystery,romance', 'comedy,girlslove,sliceoflife,ecchi', 'action,horror,mystery', 'action,comedy,girlslove,sci-fi,ecchi', 'action,adventure,mystery,sci-fi', 'adventure,mystery,supernatural', 'sci-fi,sports', 'avantgarde,awardwinning,drama,horror', 'action,comedy,sports,ecchi', 'action,drama,sci-fi', 'boyslove,drama,horror,hentai', 'romance,sliceoflife', 'awardwinning,comedy,sci-fi', 'adventure,drama,fantasy,supernatural', 'comedy,gourmet,romance', 'awardwinning,comedy,mystery,romance', 'action,drama,horror', 'comedy,girlslove,romance,sliceoflife', 'drama,supernatural,suspense', 'avantgarde,comedy,fantasy,horror', 'mystery,hentai', 'action,drama,fantasy,supernatural', 'awardwinning,drama,mystery,sci-fi,supernatural,suspense', 'drama,mystery', 'mystery,sliceoflife', 'drama,fantasy,horror,mystery,supernatural', 'adventure,comedy,romance,sci-fi', 'awardwinning,comedy,drama,fantasy', 'action,drama,mystery,romance,sci-fi', 'action,adventure,drama', 'action,adventure,comedy,fantasy,sci-fi,ecchi', 'action,adventure,comedy,mystery,sci-fi', 'boyslove,comedy,drama,supernatural,erotica', 'action,boyslove,comedy,fantasy,mystery,supernatural', 'adventure,fantasy,gourmet,sliceoflife', 'adventure,mystery,sci-fi', 'comedy', 'adventure,awardwinning,drama,fantasy', 'comedy,fantasy,girlslove,romance', 'sports,ecchi', 'action,adventure,comedy,mystery,sports', 'drama,girlslove', 'suspense', 'horror,mystery,sliceoflife,suspense', 'action,comedy,romance,supernatural,ecchi', 'action,adventure,drama,romance,supernatural', 'action,fantasy,gourmet', 'avantgarde,fantasy,romance', 'adventure,fantasy,hentai', 'boyslove,comedy,drama,romance', 'adventure,awardwinning,drama,mystery,sci-fi', 'comedy,drama,sci-fi', 'action,fantasy,supernatural', 'action,comedy,ecchi', 'action,awardwinning,drama,sci-fi,suspense', 'action,fantasy,mystery,romance', 'adventure,avantgarde,fantasy', 'action,drama,fantasy,horror,romance,sci-fi', 'action,horror,romance,supernatural', 'comedy,supernatural,ecchi', 'comedy,drama,mystery,romance,sliceoflife', 'action,horror,mystery,suspense', 'comedy,drama,romance,supernatural', 'drama,gourmet', 'action,fantasy,supernatural,ecchi', 'comedy,drama,girlslove,romance', 'action,comedy,horror,mystery,supernatural', 'adventure,avantgarde,comedy,fantasy,mystery', 'action,adventure,drama,fantasy,mystery,sci-fi', 'fantasy,gourmet', 'adventure,awardwinning', 'boyslove,drama', 'adventure,comedy,fantasy,sci-fi,supernatural', 'drama,mystery,supernatural,suspense', 'action,horror,sci-fi,ecchi', 'adventure,awardwinning,drama', 'adventure,comedy,fantasy,horror,supernatural', 'action,horror,supernatural,hentai', 'boyslove,fantasy', 'mystery,sliceoflife,supernatural', 'action,adventure,comedy', 'comedy,drama,horror,supernatural,ecchi', 'comedy,romance,sports,ecchi', 'action,avantgarde,sci-fi', 'action,adventure,mystery,supernatural', 'fantasy,horror,sci-fi,hentai', 'action,drama,fantasy,romance', 'action,adventure,comedy,fantasy,supernatural', 'action,comedy,fantasy,romance', 'adventure,sci-fi,supernatural', 'action,adventure,comedy,drama', 'action,adventure,comedy,fantasy,ecchi', 'gourmet,romance', 'adventure,sci-fi', 'comedy,romance,sports', 'action,adventure,comedy,mystery,sci-fi,ecchi', 'fantasy,romance,sci-fi', 'avantgarde,drama', 'drama,mystery,romance,sliceoflife', 'adventure,awardwinning,comedy,drama,fantasy', 'action,mystery,romance,sci-fi', 'drama,horror,mystery,supernatural', 'adventure,mystery,sci-fi,sliceoflife', 'action,adventure,comedy,fantasy,sci-fi', 'action,adventure,comedy,sci-fi,suspense', 'action,adventure,awardwinning,fantasy', 'avantgarde,boyslove,drama,romance', 'drama,fantasy,gourmet,romance', 'action,adventure,comedy,romance,supernatural,ecchi', 'drama,fantasy,mystery,sci-fi', 'action,comedy,sci-fi', 'horror,mystery', 'fantasy,horror,supernatural', 'action,adventure,comedy,sports', 'gourmet,sci-fi', 'avantgarde,mystery', 'action,adventure,drama,suspense', 'action,comedy,sci-fi,hentai', 'comedy,romance,sci-fi,supernatural', 'adventure,fantasy,mystery,supernatural', 'comedy,horror,romance,supernatural,ecchi', 'horror,hentai', 'action,adventure,fantasy,romance', 'action,comedy,sliceoflife', 'drama,fantasy', 'avantgarde,romance', 'action,adventure,fantasy,mystery,supernatural', 'action,drama,mystery,sci-fi', 'adventure,comedy,drama,sci-fi,supernatural', 'adventure,comedy,drama,sci-fi', 'action,adventure,comedy,drama,fantasy', 'drama,romance,sliceoflife,suspense,hentai', 'action,drama,fantasy,horror,mystery', 'action,comedy,sci-fi,sliceoflife', 'adventure,comedy,drama,fantasy,sci-fi', 'adventure,mystery,romance,sci-fi', 'action,fantasy,romance,ecchi', 'avantgarde,comedy,ecchi', 'drama,romance,sliceoflife', 'drama,horror,mystery', 'drama,sci-fi,sports', 'adventure,comedy,fantasy,romance,supernatural,ecchi', 'drama,mystery,suspense', 'fantasy,mystery,sci-fi,suspense', 'comedy,sliceoflife,sports', 'adventure,comedy,fantasy,romance', 'supernatural,hentai', 'action,drama,supernatural', 'adventure,drama,fantasy,sliceoflife', 'adventure,drama,fantasy,mystery,sci-fi', 'fantasy,romance,hentai', 'sliceoflife', 'action,comedy', 'action,mystery,romance,supernatural,suspense', 'adventure,horror,supernatural', 'adventure,sports', 'action,drama,horror,mystery,sci-fi,hentai', 'adventure,fantasy,sci-fi', 'adventure,fantasy,mystery', 'romance,hentai', 'awardwinning,sliceoflife,supernatural', 'action,mystery,romance,suspense', 'fantasy,suspense', 'avantgarde,awardwinning,comedy,fantasy,suspense', 'avantgarde,awardwinning,sci-fi', 'comedy,romance,hentai', 'action,comedy,fantasy,sliceoflife', 'adventure,comedy,mystery', 'action,fantasy,mystery,supernatural', 'drama', 'sci-fi', 'awardwinning,comedy,drama,romance,supernatural', 'action,drama', 'action,comedy,fantasy,horror,supernatural', 'boyslove,drama,romance,erotica', 'adventure,comedy,drama', 'action,comedy,drama,romance', 'mystery,supernatural', 'adventure,avantgarde', 'fantasy,horror,mystery,supernatural', 'drama,romance,sci-fi,sliceoflife', 'comedy,sci-fi,sliceoflife', 'sci-fi,supernatural', 'adventure,awardwinning,fantasy', 'girlslove', 'drama,sci-fi,ecchi', 'action,drama,mystery,sci-fi,suspense', 'drama,mystery,sci-fi,supernatural', 'awardwinning,comedy,mystery,sci-fi', 'horror,sci-fi,supernatural,hentai', 'horror,supernatural,hentai', 'horror,romance,supernatural,ecchi', 'fantasy,sliceoflife', 'avantgarde,fantasy,sci-fi', 'action,adventure,sliceoflife', 'action,adventure,drama,horror,sci-fi', 'action,sports,ecchi', 'adventure,comedy,fantasy', 'comedy,mystery,sci-fi', 'drama,fantasy,horror,mystery', 'adventure,comedy,fantasy,sports', 'adventure,fantasy,suspense', 'action,fantasy,romance,sci-fi', 'adventure,boyslove,comedy', 'fantasy,horror,mystery', 'mystery,romance,supernatural', 'adventure,comedy,fantasy,romance,supernatural', 'awardwinning,comedy,drama,sci-fi,sports', 'adventure,comedy,mystery,sports', 'adventure,comedy,sci-fi', 'adventure,supernatural', 'avantgarde,sliceoflife', 'action,mystery,supernatural,suspense', 'boyslove,drama,girlslove,romance,sliceoflife', 'awardwinning,comedy,drama,sliceoflife,supernatural', 'adventure,drama,mystery,sliceoflife', 'comedy,drama,sliceoflife,supernatural', 'action,sports', 'adventure,comedy,fantasy,sliceoflife', 'action,adventure,comedy,fantasy,mystery', 'romance,sports', 'action,adventure,fantasy,mystery,sci-fi', 'action,mystery,suspense', 'action,awardwinning,mystery,sci-fi,suspense', 'awardwinning,comedy,drama', 'drama,horror,erotica', 'action,awardwinning,supernatural', 'action,drama,horror,mystery,sci-fi,suspense', 'action,adventure,drama,fantasy,romance', 'drama,romance,sports,supernatural', 'comedy,sci-fi,supernatural', 'fantasy,girlslove,sliceoflife', 'drama,romance,hentai', 'awardwinning,drama,romance', 'fantasy,horror,hentai', 'comedy,sci-fi,sliceoflife,sports', 'adventure,comedy,horror', 'action,adventure', 'awardwinning,comedy,sliceoflife', 'romance,sliceoflife,supernatural', 'drama,sliceoflife,supernatural', 'drama,fantasy,romance,ecchi', 'avantgarde,drama,horror', 'awardwinning,sliceoflife', 'action,girlslove,horror,sci-fi,supernatural', 'action,fantasy,horror', 'comedy,drama,sports', 'adventure,drama,fantasy,romance,sci-fi', 'adventure,comedy,hentai', 'action,boyslove,supernatural', 'action,fantasy,mystery,sci-fi', 'adventure,mystery', 'awardwinning,drama,horror,sci-fi', 'drama,romance,sci-fi', 'awardwinning,drama,supernatural', 'action,comedy,fantasy,hentai', 'action,fantasy,suspense', 'action,drama,supernatural,suspense', 'adventure,comedy,romance,supernatural,ecchi', 'adventure,horror,mystery']\n",
      "{'adventure', 'sliceoflife', 'action', 'romance', 'erotica', 'ecchi', 'comedy', 'suspense', 'supernatural', 'fantasy', 'hentai', 'drama', 'sci-fi', 'boyslove', 'sports', 'avantgarde', 'horror', 'girlslove', 'awardwinning', 'unknown', 'mystery', 'gourmet'}\n"
     ]
    }
   ],
   "source": [
    "# predict the genre of the anime\n",
    "\n",
    "# get the first anime synopsis\n",
    "anime_synopsis = test['Synopsis'].iloc[0]\n",
    "anime_name = test['Name'].iloc[0]\n",
    "anime_genre = test['Genres'].iloc[0]\n",
    "\n",
    "# all possible genres\n",
    "all_genres = list(set(data['Genres'].str.cat(sep='|').split('|')))\n",
    "\n",
    "print(all_genres)\n",
    "\n",
    "genres = set()\n",
    "for i in all_genres:\n",
    "    genres_separated = i.replace(' ', '').split(',')\n",
    "    for j in genres_separated:\n",
    "        genres.add(j)\n",
    "\n",
    "print(genres)\n",
    "\n",
    "genres = list(genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n"
     ]
    }
   ],
   "source": [
    "print(len(genres))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(anime_synopsis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeroshot_classifier = pipeline(\"zero-shot-classification\", model=\"MoritzLaurer/deberta-v3-large-zeroshot-v2.0\")  # change the model identifier here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "# Initialize results dictionary\n",
    "results = {}\n",
    "\n",
    "# Iterate over the test data with progress bar\n",
    "for index, row in tqdm(test.iterrows(), total=test.shape[0], desc=\"Processing anime\"):\n",
    "    anime_id = row['anime_id']\n",
    "    anime_synopsis = row['Synopsis']\n",
    "    anime_name = row['Name']\n",
    "    anime_genre = row['Genres']\n",
    "\n",
    "    text = 'The anime is called ' + anime_name + '. The synopsis of the anime is: ' + anime_synopsis\n",
    "    output = zeroshot_classifier(text, list(genres), multi_label=True)\n",
    "\n",
    "    anime_genre_len = len(anime_genre.split(','))\n",
    "\n",
    "    top_k_labels_predicted = output['labels'][0:anime_genre_len]\n",
    "\n",
    "    results[anime_id] = {}\n",
    "\n",
    "    for i in range(anime_genre_len):\n",
    "        genre = anime_genre.split(',')[i].strip()\n",
    "        results[anime_id][genre] = \"error\"\n",
    "        if genre in top_k_labels_predicted:\n",
    "            results[anime_id][genre] = \"correct\"\n",
    "\n",
    "# Save the results to a JSON file\n",
    "with open('results_based_model.json', 'w') as f:\n",
    "    json.dump(results, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique genres: 22\n",
      "Unique genres: ['action', 'adventure', 'avantgarde', 'awardwinning', 'boyslove', 'comedy', 'drama', 'ecchi', 'erotica', 'fantasy', 'girlslove', 'gourmet', 'hentai', 'horror', 'mystery', 'romance', 'sci-fi', 'sliceoflife', 'sports', 'supernatural', 'suspense', 'unknown']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 19924/19924 [00:03<00:00, 6194.30 examples/s]\n",
      "Map: 100%|██████████| 4981/4981 [00:00<00:00, 6418.06 examples/s]\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at MoritzLaurer/deberta-v3-large-zeroshot-v2.0 and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([2]) in the checkpoint and torch.Size([22]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([2, 1024]) in the checkpoint and torch.Size([22, 1024]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/francisco/Documents/Francisco/Faculdade/7_Semestre/processamento_lingua_natural/tpFinal/tp_final_nlp/env_py/lib/python3.11/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='7473' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [   5/7473 00:48 < 33:42:40, 0.06 it/s, Epoch 0.00/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 92\u001b[0m\n\u001b[1;32m     84\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     85\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     86\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[1;32m     87\u001b[0m     train_dataset\u001b[38;5;241m=\u001b[39mtrain_dataset,\n\u001b[1;32m     88\u001b[0m     eval_dataset\u001b[38;5;241m=\u001b[39mtest_dataset\n\u001b[1;32m     89\u001b[0m )\n\u001b[1;32m     91\u001b[0m \u001b[38;5;66;03m# Train\u001b[39;00m\n\u001b[0;32m---> 92\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Francisco/Faculdade/7_Semestre/processamento_lingua_natural/tpFinal/tp_final_nlp/env_py/lib/python3.11/site-packages/transformers/trainer.py:2171\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2169\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2170\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2171\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2172\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2173\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2174\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2175\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2176\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Francisco/Faculdade/7_Semestre/processamento_lingua_natural/tpFinal/tp_final_nlp/env_py/lib/python3.11/site-packages/transformers/trainer.py:2531\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2524\u001b[0m context \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2525\u001b[0m     functools\u001b[38;5;241m.\u001b[39mpartial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mno_sync, model\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[1;32m   2526\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch_samples) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   2527\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m!=\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mDEEPSPEED\n\u001b[1;32m   2528\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mnullcontext\n\u001b[1;32m   2529\u001b[0m )\n\u001b[1;32m   2530\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[0;32m-> 2531\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2533\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2534\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2535\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2536\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2537\u001b[0m ):\n\u001b[1;32m   2538\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2539\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/Documents/Francisco/Faculdade/7_Semestre/processamento_lingua_natural/tpFinal/tp_final_nlp/env_py/lib/python3.11/site-packages/transformers/trainer.py:3675\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs, num_items_in_batch)\u001b[0m\n\u001b[1;32m   3672\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb\u001b[38;5;241m.\u001b[39mreduce_mean()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   3674\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 3675\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3677\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m inputs\n\u001b[1;32m   3678\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   3679\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   3680\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   3681\u001b[0m ):\n",
      "File \u001b[0;32m~/Documents/Francisco/Faculdade/7_Semestre/processamento_lingua_natural/tpFinal/tp_final_nlp/env_py/lib/python3.11/site-packages/transformers/trainer.py:3731\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs, num_items_in_batch)\u001b[0m\n\u001b[1;32m   3729\u001b[0m         loss_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_items_in_batch\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m num_items_in_batch\n\u001b[1;32m   3730\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mloss_kwargs}\n\u001b[0;32m-> 3731\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3732\u001b[0m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[1;32m   3733\u001b[0m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[1;32m   3734\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpast_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/Documents/Francisco/Faculdade/7_Semestre/processamento_lingua_natural/tpFinal/tp_final_nlp/env_py/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Francisco/Faculdade/7_Semestre/processamento_lingua_natural/tpFinal/tp_final_nlp/env_py/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Documents/Francisco/Faculdade/7_Semestre/processamento_lingua_natural/tpFinal/tp_final_nlp/env_py/lib/python3.11/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:1175\u001b[0m, in \u001b[0;36mDebertaV2ForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1167\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1168\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1169\u001b[0m \u001b[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[1;32m   1170\u001b[0m \u001b[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[1;32m   1171\u001b[0m \u001b[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[1;32m   1172\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1173\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1175\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeberta\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1176\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1177\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1178\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1179\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1180\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1181\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1182\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1183\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1184\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1186\u001b[0m encoder_layer \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1187\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(encoder_layer)\n",
      "File \u001b[0;32m~/Documents/Francisco/Faculdade/7_Semestre/processamento_lingua_natural/tpFinal/tp_final_nlp/env_py/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Francisco/Faculdade/7_Semestre/processamento_lingua_natural/tpFinal/tp_final_nlp/env_py/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Documents/Francisco/Faculdade/7_Semestre/processamento_lingua_natural/tpFinal/tp_final_nlp/env_py/lib/python3.11/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:870\u001b[0m, in \u001b[0;36mDebertaV2Model.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    860\u001b[0m     token_type_ids \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(input_shape, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m    862\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(\n\u001b[1;32m    863\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m    864\u001b[0m     token_type_ids\u001b[38;5;241m=\u001b[39mtoken_type_ids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    867\u001b[0m     inputs_embeds\u001b[38;5;241m=\u001b[39minputs_embeds,\n\u001b[1;32m    868\u001b[0m )\n\u001b[0;32m--> 870\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    872\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    873\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    877\u001b[0m encoded_layers \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    879\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mz_steps \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/Documents/Francisco/Faculdade/7_Semestre/processamento_lingua_natural/tpFinal/tp_final_nlp/env_py/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Francisco/Faculdade/7_Semestre/processamento_lingua_natural/tpFinal/tp_final_nlp/env_py/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Documents/Francisco/Faculdade/7_Semestre/processamento_lingua_natural/tpFinal/tp_final_nlp/env_py/lib/python3.11/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:674\u001b[0m, in \u001b[0;36mDebertaV2Encoder.forward\u001b[0;34m(self, hidden_states, attention_mask, output_hidden_states, output_attentions, query_states, relative_pos, return_dict)\u001b[0m\n\u001b[1;32m    664\u001b[0m     output_states, attn_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    665\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    666\u001b[0m         next_kv,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    671\u001b[0m         output_attentions,\n\u001b[1;32m    672\u001b[0m     )\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 674\u001b[0m     output_states, attn_weights \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnext_kv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrelative_pos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrelative_pos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrel_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrel_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    680\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    683\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n\u001b[1;32m    684\u001b[0m     all_attentions \u001b[38;5;241m=\u001b[39m all_attentions \u001b[38;5;241m+\u001b[39m (attn_weights,)\n",
      "File \u001b[0;32m~/Documents/Francisco/Faculdade/7_Semestre/processamento_lingua_natural/tpFinal/tp_final_nlp/env_py/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Francisco/Faculdade/7_Semestre/processamento_lingua_natural/tpFinal/tp_final_nlp/env_py/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Documents/Francisco/Faculdade/7_Semestre/processamento_lingua_natural/tpFinal/tp_final_nlp/env_py/lib/python3.11/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:442\u001b[0m, in \u001b[0;36mDebertaV2Layer.forward\u001b[0;34m(self, hidden_states, attention_mask, query_states, relative_pos, rel_embeddings, output_attentions)\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    434\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    435\u001b[0m     hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    440\u001b[0m     output_attentions: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    441\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor, Optional[torch\u001b[38;5;241m.\u001b[39mTensor]]:\n\u001b[0;32m--> 442\u001b[0m     attention_output, att_matrix \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    443\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    444\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    445\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    446\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    447\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrelative_pos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrelative_pos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    448\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrel_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrel_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    449\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    450\u001b[0m     intermediate_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintermediate(attention_output)\n\u001b[1;32m    451\u001b[0m     layer_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(intermediate_output, attention_output)\n",
      "File \u001b[0;32m~/Documents/Francisco/Faculdade/7_Semestre/processamento_lingua_natural/tpFinal/tp_final_nlp/env_py/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Francisco/Faculdade/7_Semestre/processamento_lingua_natural/tpFinal/tp_final_nlp/env_py/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Documents/Francisco/Faculdade/7_Semestre/processamento_lingua_natural/tpFinal/tp_final_nlp/env_py/lib/python3.11/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:375\u001b[0m, in \u001b[0;36mDebertaV2Attention.forward\u001b[0;34m(self, hidden_states, attention_mask, output_attentions, query_states, relative_pos, rel_embeddings)\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    367\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    368\u001b[0m     hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    373\u001b[0m     rel_embeddings\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    374\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor, Optional[torch\u001b[38;5;241m.\u001b[39mTensor]]:\n\u001b[0;32m--> 375\u001b[0m     self_output, att_matrix \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    376\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    377\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    378\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrelative_pos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrelative_pos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrel_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrel_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    383\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m query_states \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    384\u001b[0m         query_states \u001b[38;5;241m=\u001b[39m hidden_states\n",
      "File \u001b[0;32m~/Documents/Francisco/Faculdade/7_Semestre/processamento_lingua_natural/tpFinal/tp_final_nlp/env_py/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Francisco/Faculdade/7_Semestre/processamento_lingua_natural/tpFinal/tp_final_nlp/env_py/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Documents/Francisco/Faculdade/7_Semestre/processamento_lingua_natural/tpFinal/tp_final_nlp/env_py/lib/python3.11/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:271\u001b[0m, in \u001b[0;36mDisentangledSelfAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, output_attentions, query_states, relative_pos, rel_embeddings)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;66;03m# bsz x height x length x dimension\u001b[39;00m\n\u001b[1;32m    269\u001b[0m attention_probs \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39msoftmax(attention_scores, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 271\u001b[0m attention_probs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattention_probs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    272\u001b[0m context_layer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mbmm(\n\u001b[1;32m    273\u001b[0m     attention_probs\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, attention_probs\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m), attention_probs\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)), value_layer\n\u001b[1;32m    274\u001b[0m )\n\u001b[1;32m    275\u001b[0m context_layer \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    276\u001b[0m     context_layer\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_attention_heads, context_layer\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m), context_layer\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m    277\u001b[0m     \u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;241m.\u001b[39mcontiguous()\n\u001b[1;32m    279\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/Francisco/Faculdade/7_Semestre/processamento_lingua_natural/tpFinal/tp_final_nlp/env_py/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Francisco/Faculdade/7_Semestre/processamento_lingua_natural/tpFinal/tp_final_nlp/env_py/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Documents/Francisco/Faculdade/7_Semestre/processamento_lingua_natural/tpFinal/tp_final_nlp/env_py/lib/python3.11/site-packages/torch/nn/modules/dropout.py:70\u001b[0m, in \u001b[0;36mDropout.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Francisco/Faculdade/7_Semestre/processamento_lingua_natural/tpFinal/tp_final_nlp/env_py/lib/python3.11/site-packages/torch/nn/functional.py:1425\u001b[0m, in \u001b[0;36mdropout\u001b[0;34m(input, p, training, inplace)\u001b[0m\n\u001b[1;32m   1422\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m p \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m p \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1.0\u001b[39m:\n\u001b[1;32m   1423\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdropout probability has to be between 0 and 1, but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mp\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1424\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m-> 1425\u001b[0m     _VF\u001b[38;5;241m.\u001b[39mdropout_(\u001b[38;5;28minput\u001b[39m, p, training) \u001b[38;5;28;01mif\u001b[39;00m inplace \u001b[38;5;28;01melse\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1426\u001b[0m )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "import pandas as pd\n",
    "\n",
    "# Split into train and test sets\n",
    "train = data.sample(frac=0.8, random_state=0)\n",
    "test = data.drop(train.index)\n",
    "\n",
    "# Extract all unique genres from the ENTIRE dataset\n",
    "all_genres = set()\n",
    "for genres in data['Genres'].dropna():\n",
    "    all_genres.update(g.strip() for g in genres.split(','))  # Preserve spaces within genre names\n",
    "unique_genres = sorted(all_genres)\n",
    "\n",
    "\n",
    "# Verify the number of unique genres\n",
    "print(\"Number of unique genres:\", len(unique_genres)) \n",
    "print(\"Unique genres:\", unique_genres)\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocess(df):\n",
    "    df['text'] = 'The synopsis of the anime is: ' + df['Synopsis']\n",
    "    \n",
    "    # Encode labels as binary vectors\n",
    "    genre_to_id = {genre: idx for idx, genre in enumerate(unique_genres)}\n",
    "    \n",
    "    def encode_labels(genres):\n",
    "        labels = [0] * len(unique_genres)\n",
    "        if isinstance(genres, str):  # Check if genres is a string\n",
    "            for genre in genres.split(','):\n",
    "                labels[genre_to_id[genre.strip()]] = 1\n",
    "        return labels\n",
    "    \n",
    "    df['labels'] = df['Genres'].apply(encode_labels)\n",
    "    return df\n",
    "\n",
    "# Preprocess train and test datasets\n",
    "train = preprocess(train)\n",
    "test = preprocess(test)\n",
    "\n",
    "# Convert to Hugging Face Dataset\n",
    "train_dataset = Dataset.from_pandas(train[['text', 'labels']])\n",
    "test_dataset = Dataset.from_pandas(test[['text', 'labels']])\n",
    "\n",
    "# Tokenizer\n",
    "model_name = \"MoritzLaurer/deberta-v3-large-zeroshot-v2.0\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def tokenize(batch):\n",
    "    tokenized = tokenizer(batch['text'], padding=\"max_length\", truncation=True, max_length=512)\n",
    "    tokenized[\"labels\"] = batch[\"labels\"]\n",
    "    return tokenized\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize, batched=True)\n",
    "test_dataset = test_dataset.map(tokenize, batched=True)\n",
    "\n",
    "# Load Pre-trained Model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=len(unique_genres),  # Set to the number of unique genres (42)\n",
    "    ignore_mismatched_sizes=True    # Ignore size mismatches\n",
    ")\n",
    "\n",
    "# Freeze pre-trained layers\n",
    "for param in model.base_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Training Arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    disable_tqdm=False, \n",
    ")\n",
    "\n",
    "# Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset\n",
    ")\n",
    "\n",
    "# Train\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained('./model/fine-tuned-anime-genre-model')\n",
    "tokenizer.save_pretrained('./model/fine-tuned-anime-genre-model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "model_path = './model/fine-tuned-anime-genre-model'\n",
    "zeroshot_classifier = pipeline(\"zero-shot-classification\", model=model_path)\n",
    "\n",
    "# Define genres\n",
    "#genres = sorted(set(g.strip() for genre_list in data['Genres'].dropna() for g in genre_list.split(',')))\n",
    "\n",
    "# Initialize results dictionary\n",
    "results = {}\n",
    "\n",
    "# Iterate over the test data with progress bar\n",
    "for index, row in tqdm(test.iterrows(), total=test.shape[0], desc=\"Processing anime\"):\n",
    "    anime_id = row['anime_id']\n",
    "    anime_synopsis = row['Synopsis']\n",
    "    anime_name = row['Name']\n",
    "    anime_genre = row['Genres']\n",
    "\n",
    "    # Prepare input text for classification\n",
    "    text = f\"The anime is called {anime_name}. The synopsis of the anime is: {anime_synopsis}\"\n",
    "\n",
    "    # Predict genres using the fine-tuned model\n",
    "    output = zeroshot_classifier(text, unique_genres, multi_label=True)\n",
    "\n",
    "    # Extract predicted genres\n",
    "    anime_genre_len = len(anime_genre.split(','))\n",
    "    top_k_labels_predicted = output['labels'][0:anime_genre_len]\n",
    "\n",
    "    \"\"\" print(\"Anime ID \", anime_id)\n",
    "    print(\"Genre \", anime_genre.split(','))\n",
    "    print(\"Top k labels predicted \", top_k_labels_predicted) \"\"\"\n",
    "\n",
    "    # Store results\n",
    "    results[anime_id] = {}\n",
    "    for i in range(anime_genre_len):\n",
    "        genre = anime_genre.split(',')[i].lower()\n",
    "        results[anime_id][genre] = \"error\"\n",
    "        if genre in top_k_labels_predicted:\n",
    "            results[anime_id][genre] = \"correct\"\n",
    "    \n",
    "    \"\"\" if len(results) == 10:\n",
    "        break \"\"\"\n",
    "\n",
    "# Save the results to a JSON file\n",
    "with open('results_finetuned_model.json', 'w') as f:\n",
    "    json.dump(results, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "zeroshot_classifier = pipeline(\"zero-shot-classification\", model=\"MoritzLaurer/deberta-v3-large-zeroshot-v2.0\")  # change the model identifier here\n",
    "\n",
    "genre_keywords = {\n",
    "    \"adventure\": [\"quest\", \"journey\", \"explore\", \"discovery\", \"expedition\"],\n",
    "    \"sliceoflife\": [\"school\", \"daily life\", \"relationships\", \"emotions\", \"youth\"],\n",
    "    \"action\": [\"fight\", \"battle\", \"combat\", \"war\", \"violence\", \"hero\"],\n",
    "    \"romance\": [\"love\", \"passion\", \"relationship\", \"heart\", \"romantic\"],\n",
    "    \"erotica\": [\"sensual\", \"explicit\", \"adult\", \"intimate\"],\n",
    "    \"ecchi\": [\"fanservice\", \"sexy\", \"provocative\"],\n",
    "    \"comedy\": [\"funny\", \"joke\", \"laugh\", \"humor\", \"silly\"],\n",
    "    \"suspense\": [\"mystery\", \"thriller\", \"suspense\", \"tension\", \"cliffhanger\"],\n",
    "    \"supernatural\": [\"ghost\", \"superpower\", \"vampire\", \"magic\", \"witch\", \"occult\"],\n",
    "    \"fantasy\": [\"magic\", \"dragon\", \"wizard\", \"sword\", \"medieval\", \"mythical\"],\n",
    "    \"hentai\": [\"adult\", \"explicit\", \"mature\", \"sexual\", \"forbidden\"],\n",
    "    \"drama\": [\"conflict\", \"emotions\", \"heartbreak\", \"struggle\", \"family\", \"tragedy\"],\n",
    "    \"sci-fi\": [\"space\", \"future\", \"alien\", \"robot\", \"science\", \"technology\"],\n",
    "    \"boyslove\": [\"love\", \"romantic\", \"relationship\", \"boys\"],\n",
    "    \"sports\": [\"game\", \"team\", \"competition\", \"sports\", \"training\", \"match\"],\n",
    "    \"avantgarde\": [\"art\", \"experimental\", \"unique\", \"artsy\", \"abstract\", \"avant-garde\"],\n",
    "    \"horror\": [\"scary\", \"monster\", \"ghost\", \"screaming\", \"fear\", \"gore\"],\n",
    "    \"girlslove\": [\"love\", \"romance\", \"relationship\", \"girls\"],\n",
    "    \"awardwinning\": [\"award\", \"nomination\", \"critically acclaimed\"],\n",
    "    \"unknown\": [\"unknown\", \"mystery\", \"confusion\"],\n",
    "    \"mystery\": [\"detective\", \"investigation\", \"puzzle\", \"whodunit\", \"crime\"],\n",
    "    \"gourmet\": [\"food\", \"cooking\", \"restaurant\", \"chef\", \"gourmet\", \"culinary\"],\n",
    "}\n",
    "\n",
    "# USAR TF-IDF PRA DESCOBRIR PALAVRAS??\n",
    "\n",
    "def add_context_based_on_keywords(synopsis, genre_keywords):\n",
    "    context = \"\"\n",
    "    for genre, keywords in genre_keywords.items():\n",
    "        if any(keyword.lower() in synopsis.lower() for keyword in keywords):\n",
    "            # Add genre context if any keyword is found\n",
    "            context += f\" This anime involves {genre.lower()} elements, including {', '.join(keywords)}.\"\n",
    "\n",
    "    # Return the augmented synopsis with additional context\n",
    "    return synopsis + context\n",
    "\n",
    "# Define genres\n",
    "#genres = sorted(set(g.strip() for genre_list in data['Genres'].dropna() for g in genre_list.split(',')))\n",
    "\n",
    "# Initialize results dictionary\n",
    "results = {}\n",
    "\n",
    "# Iterate over the test data with progress bar\n",
    "for index, row in tqdm(test.iterrows(), total=test.shape[0], desc=\"Processing anime\"):\n",
    "    anime_id = row['anime_id']\n",
    "    anime_synopsis = row['Synopsis']\n",
    "    anime_name = row['Name']\n",
    "    anime_genre = row['Genres']\n",
    "\n",
    "    # Prepare input text for classification\n",
    "    augmented_text = add_context_based_on_keywords(anime_synopsis, genre_keywords)\n",
    "\n",
    "    text = 'The anime is called ' + anime_name + '. The synopsis of the anime is: ' + anime_synopsis + \". \" + augmented_text\n",
    "\n",
    "    # Predict genres using the fine-tuned model\n",
    "    output = zeroshot_classifier(text, unique_genres, multi_label=True)\n",
    "\n",
    "    # Extract predicted genres\n",
    "    anime_genre_len = len(anime_genre.split(','))\n",
    "    top_k_labels_predicted = output['labels'][0:anime_genre_len]\n",
    "\n",
    "    print(\"Anime ID \", anime_id)\n",
    "    print(\"Genre \", anime_genre.split(','))\n",
    "    print(\"Top k labels predicted \", top_k_labels_predicted)\n",
    "\n",
    "    # Store results\n",
    "    results[anime_id] = {}\n",
    "    for i in range(anime_genre_len):\n",
    "        genre = anime_genre.split(',')[i].lower()\n",
    "        results[anime_id][genre] = \"error\"\n",
    "        if genre in top_k_labels_predicted:\n",
    "            results[anime_id][genre] = \"correct\"\n",
    "    \n",
    "    if len(results) == 10:\n",
    "        break\n",
    "\n",
    "# Save the results to a JSON file\n",
    "with open('results_context_classification.json', 'w') as f:\n",
    "    json.dump(results, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_py",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
